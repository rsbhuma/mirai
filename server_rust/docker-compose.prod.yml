version: '3.8'

services:
  # Load Balancer (HAProxy)
  load-balancer:
    image: haproxy:2.8-alpine
    ports:
      - "80:80"
      - "443:443"
      - "8404:8404"  # HAProxy stats
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./ssl:/etc/ssl/certs:ro
    depends_on:
      - app-1
      - app-2
      - app-3
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Application instances (horizontal scaling)
  app-1:
    build:
      context: .
      dockerfile: Dockerfile.prod
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres-primary:5432/community_coin_db
      - DATABASE_READ_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres-replica:5432/community_coin_db
      - REDIS_URL=redis://redis-cluster:6379
      - SERVER_PORT=8080
      - INSTANCE_ID=app-1
      - RUST_LOG=info
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - SOLANA_RPC_URL=${SOLANA_RPC_URL}
    depends_on:
      - postgres-primary
      - redis-cluster
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  app-2:
    build:
      context: .
      dockerfile: Dockerfile.prod
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres-primary:5432/community_coin_db
      - DATABASE_READ_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres-replica:5432/community_coin_db
      - REDIS_URL=redis://redis-cluster:6379
      - SERVER_PORT=8080
      - INSTANCE_ID=app-2
      - RUST_LOG=info
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - SOLANA_RPC_URL=${SOLANA_RPC_URL}
    depends_on:
      - postgres-primary
      - redis-cluster
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  app-3:
    build:
      context: .
      dockerfile: Dockerfile.prod
    environment:
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres-primary:5432/community_coin_db
      - DATABASE_READ_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres-replica:5432/community_coin_db
      - REDIS_URL=redis://redis-cluster:6379
      - SERVER_PORT=8080
      - INSTANCE_ID=app-3
      - RUST_LOG=info
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_ANON_KEY=${SUPABASE_ANON_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - SOLANA_RPC_URL=${SOLANA_RPC_URL}
    depends_on:
      - postgres-primary
      - redis-cluster
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQL Primary (Master)
  postgres-primary:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: community_coin_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    volumes:
      - postgres_primary_data:/var/lib/postgresql/data
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5

  # PostgreSQL Read Replica
  postgres-replica:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: community_coin_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGUSER: postgres
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
    command: >
      bash -c "
      if [ ! -f /var/lib/postgresql/data/PG_VERSION ]; then
        pg_basebackup -h postgres-primary -D /var/lib/postgresql/data -U replicator -v -P -W
        echo \"standby_mode = 'on'\" >> /var/lib/postgresql/data/recovery.conf
        echo \"primary_conninfo = 'host=postgres-primary port=5432 user=replicator'\" >> /var/lib/postgresql/data/recovery.conf
      fi
      postgres
      "
    depends_on:
      - postgres-primary
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '1.5'

  # Redis Cluster (High Availability)
  redis-cluster:
    image: redis:7-alpine
    command: >
      redis-server
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis_cluster_data:/data
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Sentinel for HA
  redis-sentinel:
    image: redis:7-alpine
    command: >
      redis-sentinel /etc/redis/sentinel.conf
    volumes:
      - ./redis-sentinel.conf:/etc/redis/sentinel.conf:ro
    depends_on:
      - redis-cluster
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:v2.40.0
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Grafana for visualization
  grafana:
    image: grafana/grafana:9.3.0
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:v1.5.0
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # Elasticsearch for centralized logging
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Logstash for log processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
    depends_on:
      - elasticsearch
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:1.41
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Auto-scaler service
  autoscaler:
    build:
      context: ./autoscaler
      dockerfile: Dockerfile
    environment:
      - DOCKER_HOST=unix:///var/run/docker.sock
      - PROMETHEUS_URL=http://prometheus:9090
      - MIN_INSTANCES=3
      - MAX_INSTANCES=10
      - CPU_THRESHOLD=70
      - MEMORY_THRESHOLD=80
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - app-network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

volumes:
  postgres_primary_data:
    driver: local
  postgres_replica_data:
    driver: local
  redis_cluster_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16 